import os
import tensorflow as tf
import numpy as np
import cv2
import joblib
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (classification_report, confusion_matrix,
                             precision_score, recall_score, f1_score,
                             average_precision_score, accuracy_score)
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation, Input, Conv2D, MaxPooling2D, \
    UpSampling2D, concatenate, Conv2DTranspose
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, Callback
from tensorflow.keras.regularizers import l2
from skimage.feature import local_binary_pattern, graycomatrix, graycoprops
from scipy import ndimage as ndi
import random
from sklearn.ensemble import VotingClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
import json
import glob
from PIL import Image
import shutil
from sklearn.model_selection import train_test_split
from sklearn.base import BaseEstimator, ClassifierMixin
from scipy.stats import moment
from skimage.measure import regionprops
import warnings
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
from datetime import datetime

warnings.filterwarnings('ignore')

# ========== å¼ºåˆ¶GPUå†…å­˜ä¼˜åŒ– ==========
print("ğŸš€ é…ç½®GPUå†…å­˜ä½¿ç”¨ç­–ç•¥...")

# ç¦ç”¨å†…å­˜å¢é•¿ï¼Œè®©TensorFlowç›´æ¥åˆ†é…å¤§å—å†…å­˜
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, False)

        # è®¾ç½®GPUå†…å­˜é™åˆ¶ä¸º14GBï¼ˆç»™ç³»ç»Ÿç•™4GBï¼‰
        tf.config.set_logical_device_configuration(
            gpus[0],
            [tf.config.LogicalDeviceConfiguration(memory_limit=14 * 1024)]
        )
        print(f"âœ… GPUå†…å­˜é…ç½®: åˆ†é…14GBå†…å­˜ï¼Œç¦ç”¨å†…å­˜å¢é•¿")
    except RuntimeError as e:
        print(f"âŒ GPUé…ç½®é”™è¯¯: {e}")
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print("âœ… å›é€€åˆ°å†…å­˜å¢é•¿æ¨¡å¼")
else:
    print("âš ï¸ æœªæ£€æµ‹åˆ°GPUè®¾å¤‡ï¼Œä½¿ç”¨CPUè®­ç»ƒ")

# è®¾ç½®ç¯å¢ƒå˜é‡ä¼˜åŒ–å†…å­˜åˆ†é…
os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'
os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'false'

# éªŒè¯GPUçŠ¶æ€
print(f"ğŸ” GPUè®¾å¤‡æ£€æµ‹: {len(gpus)} ä¸ªç‰©ç†GPU")

# æ¸…é™¤ä¹‹å‰çš„ä¼šè¯
tf.keras.backend.clear_session()

print("ğŸ¯ GPUå†…å­˜é…ç½®å®Œæˆ")

# å­—ä½“é…ç½®
plt.rcParams["font.family"] = ["SimHei", "Microsoft YaHei", "Arial", "sans-serif"]
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.figsize'] = (10, 8)

# é…ç½®å‚æ•°ï¼ˆä¼˜åŒ–åçš„å‚æ•°ï¼‰
LABELME_SOURCE_DIR = r"C:\Users\huanglei\PycharmProjects\PythonProject1\semi_auto_labeling\gpu_auto_labels"
LABELME_TRAIN_DIR = r"C:\Users\huanglei\PycharmProjects\PythonProject1\labelme_train_annotations"
LABELME_VAL_DIR = r"C:\Users\huanglei\PycharmProjects\PythonProject1\labelme_val_annotations"
LABELME_TRAIN_OUTPUT = r"C:\Users\huanglei\PycharmProjects\PythonProject1\labelme_train_data"
LABELME_VAL_OUTPUT = r"C:\Users\huanglei\PycharmProjects\PythonProject1\labelme_val_data"
SEGMENTATION_MODEL_PATH = r"C:\Users\huanglei\PycharmProjects\PythonProject1\models\segmentation_model.h5"
SEGMENTED_OUTPUT_PATH = r"C:\Users\huanglei\PycharmProjects\PythonProject1\segmented_data"

AUGMENTED_TRAIN_PATH = r"C:\Users\huanglei\PycharmProjects\PythonProject1\final_augmented_train"
AUGMENTED_VAL_PATH = r"C:\Users\huanglei\PycharmProjects\PythonProject1\final_augmented_val"
MODEL_SAVE_PATH = r"C:\Users\huanglei\PycharmProjects\PythonProject1\models\welding_defect_model.h5"
SCALER_SAVE_PATH = r"C:\Users\huanglei\PycharmProjects\PythonProject1\models\feature_scaler.pkl"
ENSEMBLE_SAVE_PATH = r"C:\Users\huanglei\PycharmProjects\PythonProject1\models\ensemble_model.pkl"
PLOT_SAVE_PATH = r"C:\Users\huanglei\PycharmProjects\PythonProject1\plots"

# ä¼˜åŒ–åçš„å‚æ•°
IMG_SIZE = (128, 128)  # è°ƒæ•´ä¸ºé€‚ä¸­çš„å°ºå¯¸
SEG_INPUT_SIZE = (256, 256, 3)
CLASS_NAMES = ['crack', 'porosity', 'spatter']
CLASS_NAMES_CN = ['è£‚çº¹', 'æ°”å­”', 'é£æº…']
NUM_CLASSES = len(CLASS_NAMES)
EPOCHS = 100  # å‡å°‘è®­ç»ƒè½®æ¬¡
BATCH_SIZE = 8  # é€‚ä¸­çš„æ‰¹é‡å¤§å°
LEARNING_RATE = 0.001
SEG_EPOCHS = 50
SEG_BATCH_SIZE = 4


# ========================== åŸºç¡€å·¥å…·å‡½æ•° ==========================
def create_necessary_directories():
    """åˆ›å»ºå¿…è¦ç›®å½•"""
    directories = [
        AUGMENTED_TRAIN_PATH, AUGMENTED_VAL_PATH,
        os.path.dirname(MODEL_SAVE_PATH), PLOT_SAVE_PATH,
        LABELME_TRAIN_OUTPUT, LABELME_VAL_OUTPUT,
        SEGMENTED_OUTPUT_PATH, os.path.dirname(SCALER_SAVE_PATH),
        LABELME_TRAIN_DIR, LABELME_VAL_DIR
    ]

    for directory in directories:
        if directory and not os.path.exists(directory):
            os.makedirs(directory, exist_ok=True)
            print(f"åˆ›å»ºç›®å½•: {directory}")

    return True


def auto_distribute_labelme_data():
    """è‡ªåŠ¨å°†æ ‡æ³¨æ–‡ä»¶åˆ†é…åˆ°è®­ç»ƒé›†å’ŒéªŒè¯é›†"""
    print("ğŸ”„ è‡ªåŠ¨åˆ†é…LabelMeæ ‡æ³¨æ•°æ®...")

    # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
    os.makedirs(LABELME_TRAIN_DIR, exist_ok=True)
    os.makedirs(LABELME_VAL_DIR, exist_ok=True)

    # è·å–æ‰€æœ‰JSONæ–‡ä»¶
    json_files = glob.glob(os.path.join(LABELME_SOURCE_DIR, "*.json"))

    if not json_files:
        print(f"é”™è¯¯: åœ¨ {LABELME_SOURCE_DIR} ä¸­æœªæ‰¾åˆ°JSONæ–‡ä»¶")
        return False

    print(f"æ‰¾åˆ° {len(json_files)} ä¸ªæ ‡æ³¨æ–‡ä»¶")

    # æŒ‰ç±»åˆ«ç»„ç»‡æ–‡ä»¶
    class_files = {class_name: [] for class_name in CLASS_NAMES}
    other_files = []

    for json_file in json_files:
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # è·å–å›¾åƒæ–‡ä»¶å
            image_filename = data['imagePath']
            image_path = os.path.join(LABELME_SOURCE_DIR, image_filename)

            # æ£€æŸ¥å›¾åƒæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(image_path):
                print(f"è­¦å‘Š: å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨ {image_path}")
                continue

            # æ£€æŸ¥æ ‡æ³¨ç±»åˆ«
            shapes = data.get('shapes', [])
            valid_classes = []

            for shape in shapes:
                label = shape['label']
                if label in CLASS_NAMES:
                    valid_classes.append(label)

            if valid_classes:
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªæœ‰æ•ˆç±»åˆ«
                main_class = valid_classes[0]
                class_files[main_class].append((json_file, image_path))
            else:
                other_files.append((json_file, image_path))

        except Exception as e:
            print(f"å¤„ç†æ–‡ä»¶ {json_file} æ—¶å‡ºé”™: {str(e)}")
            continue

    # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
    print("\nğŸ“Š ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡:")
    for class_name in CLASS_NAMES:
        print(f"  {class_name}: {len(class_files[class_name])} ä¸ªæ ·æœ¬")

    # æŒ‰ç±»åˆ«åˆ†é…è®­ç»ƒé›†å’ŒéªŒè¯é›†
    train_files = []
    val_files = []

    for class_name in CLASS_NAMES:
        files = class_files[class_name]
        if len(files) < 2:
            print(f"è­¦å‘Š: ç±»åˆ« {class_name} æ ·æœ¬è¿‡å°‘ï¼Œå…¨éƒ¨ç”¨äºè®­ç»ƒ")
            train_files.extend(files)
            continue

        # æŒ‰8:2åˆ†å‰²
        train_class, val_class = train_test_split(
            files, test_size=0.2, random_state=42
        )
        train_files.extend(train_class)
        val_files.extend(val_class)

    print(f"\nğŸ“ æ•°æ®åˆ†é…ç»“æœ:")
    print(f"  è®­ç»ƒé›†: {len(train_files)} ä¸ªæ ·æœ¬")
    print(f"  éªŒè¯é›†: {len(val_files)} ä¸ªæ ·æœ¬")

    # å¤åˆ¶æ–‡ä»¶åˆ°å¯¹åº”ç›®å½•
    def copy_files(file_list, target_dir):
        """å¤åˆ¶æ–‡ä»¶åˆ°ç›®æ ‡ç›®å½•"""
        for json_file, image_path in file_list:
            try:
                # å¤åˆ¶JSONæ–‡ä»¶
                json_filename = os.path.basename(json_file)
                target_json = os.path.join(target_dir, json_filename)
                shutil.copy2(json_file, target_json)

                # å¤åˆ¶å›¾åƒæ–‡ä»¶
                image_filename = os.path.basename(image_path)
                target_image = os.path.join(target_dir, image_filename)
                shutil.copy2(image_path, target_image)

            except Exception as e:
                print(f"å¤åˆ¶æ–‡ä»¶æ—¶å‡ºé”™: {e}")

    # å¤åˆ¶è®­ç»ƒé›†æ–‡ä»¶
    print("å¤åˆ¶è®­ç»ƒé›†æ–‡ä»¶...")
    copy_files(train_files, LABELME_TRAIN_DIR)

    # å¤åˆ¶éªŒè¯é›†æ–‡ä»¶
    print("å¤åˆ¶éªŒè¯é›†æ–‡ä»¶...")
    copy_files(val_files, LABELME_VAL_DIR)

    print("âœ… LabelMeæ•°æ®è‡ªåŠ¨åˆ†é…å®Œæˆ")
    return True


def load_labelme_data(labelme_dir, output_img_dir):
    """å°†LabelMe JSONæ ‡æ³¨æ–‡ä»¶è½¬æ¢ä¸ºæ¨¡å‹å¯ç”¨çš„å›¾åƒå’Œæ ‡ç­¾"""
    # åˆ›å»ºè¾“å‡ºç›®å½•
    for class_name in CLASS_NAMES:
        class_dir = os.path.join(output_img_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)

    json_files = glob.glob(os.path.join(labelme_dir, "*.json"))

    if not json_files:
        print(f"è­¦å‘Š: åœ¨ {labelme_dir} ä¸­æœªæ‰¾åˆ°JSONæ–‡ä»¶")
        return output_img_dir

    processed_count = 0
    error_count = 0

    print(f"æ­£åœ¨å¤„ç† {len(json_files)} ä¸ªLabelMe JSONæ–‡ä»¶...")

    for json_file in json_files:
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # è·å–å›¾åƒè·¯å¾„
            image_path = data['imagePath']
            image_dir = os.path.dirname(json_file)
            full_image_path = os.path.join(image_dir, image_path)

            # è¯»å–å›¾åƒ
            if not os.path.exists(full_image_path):
                print(f"è­¦å‘Š: å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨ {full_image_path}")
                continue

            image = cv2.imdecode(np.fromfile(full_image_path, dtype=np.uint8), cv2.IMREAD_COLOR)
            if image is None:
                print(f"è­¦å‘Š: æ— æ³•è¯»å–å›¾åƒ {full_image_path}")
                continue

            # è·å–æ ‡æ³¨ä¿¡æ¯
            shapes = data.get('shapes', [])
            if not shapes:
                print(f"è­¦å‘Š: æ–‡ä»¶ {json_file} ä¸­æ²¡æœ‰æ ‡æ³¨")
                continue

            # å¤„ç†æ¯ä¸ªæ ‡æ³¨
            for i, shape in enumerate(shapes):
                label = shape['label']
                points = shape['points']

                # æ£€æŸ¥æ ‡ç­¾æ˜¯å¦åœ¨ç›®æ ‡ç±»åˆ«ä¸­
                if label not in CLASS_NAMES:
                    print(f"è­¦å‘Š: æœªçŸ¥æ ‡ç­¾ '{label}'ï¼Œè·³è¿‡")
                    continue

                # åˆ›å»ºè¾¹ç•Œæ¡†æˆ–è£å‰ªåŒºåŸŸ
                points_array = np.array(points, dtype=np.float32)
                x_min, y_min = np.min(points_array, axis=0)
                x_max, y_max = np.max(points_array, axis=0)

                # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
                x_min = max(0, int(x_min))
                y_min = max(0, int(y_min))
                x_max = min(image.shape[1], int(x_max))
                y_max = min(image.shape[0], int(y_max))

                # è£å‰ªç¼ºé™·åŒºåŸŸ
                if x_max > x_min and y_max > y_min:
                    defect_region = image[y_min:y_max, x_min:x_max]

                    # è°ƒæ•´å›¾åƒå¤§å°
                    if defect_region.size > 0:
                        defect_region = cv2.resize(defect_region, IMG_SIZE)

                        # ä¿å­˜è£å‰ªçš„å›¾åƒ
                        base_name = os.path.splitext(os.path.basename(json_file))[0]
                        output_filename = f"{base_name}_{i}.jpg"
                        output_path = os.path.join(output_img_dir, label, output_filename)

                        # ä½¿ç”¨OpenCVä¿å­˜ï¼Œç¡®ä¿ä¸­æ–‡è·¯å¾„å…¼å®¹
                        cv2.imencode('.jpg', defect_region)[1].tofile(output_path)
                        processed_count += 1

        except Exception as e:
            print(f"å¤„ç†æ–‡ä»¶ {json_file} æ—¶å‡ºé”™: {str(e)}")
            error_count += 1
            continue

    print(f"LabelMeæ•°æ®è½¬æ¢å®Œæˆ: æˆåŠŸå¤„ç† {processed_count} ä¸ªç¼ºé™·ï¼Œé”™è¯¯ {error_count} ä¸ª")
    return output_img_dir


def create_dataset_from_labelme():
    """ä»LabelMeæ ‡æ³¨åˆ›å»ºè®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†"""
    print("ğŸ”„ å¼€å§‹è½¬æ¢LabelMeæ ‡æ³¨æ•°æ®...")

    # é¦–å…ˆè‡ªåŠ¨åˆ†é…æ•°æ®
    if not auto_distribute_labelme_data():
        print("âŒ LabelMeæ•°æ®åˆ†é…å¤±è´¥")
        return None, None

    # è½¬æ¢è®­ç»ƒæ•°æ®
    print("è½¬æ¢è®­ç»ƒæ•°æ®...")
    train_output_dir = LABELME_TRAIN_OUTPUT
    load_labelme_data(LABELME_TRAIN_DIR, train_output_dir)

    # è½¬æ¢éªŒè¯æ•°æ®
    print("è½¬æ¢éªŒè¯æ•°æ®...")
    val_output_dir = LABELME_VAL_OUTPUT
    load_labelme_data(LABELME_VAL_DIR, val_output_dir)

    return train_output_dir, val_output_dir


# ========================== é«˜çº§è®­ç»ƒç›‘æ§å›è°ƒ ==========================
class AdvancedTrainingMonitor(Callback):
    """é«˜çº§è®­ç»ƒç›‘æ§å›è°ƒï¼Œå®æ—¶æ˜¾ç¤ºå…³é”®æŒ‡æ ‡"""

    def __init__(self, validation_data, class_names_cn):
        super().__init__()
        self.X_val, self.y_val = validation_data
        self.class_names_cn = class_names_cn
        self.best_map50 = 0
        self.best_accuracy = 0
        self.epoch_times = []

    def on_epoch_begin(self, epoch, logs=None):
        self.epoch_start_time = time.time()

    def on_epoch_end(self, epoch, logs=None):
        # è®¡ç®—epochæ—¶é—´
        epoch_time = time.time() - self.epoch_start_time
        self.epoch_times.append(epoch_time)
        avg_time = np.mean(self.epoch_times[-5:]) if len(self.epoch_times) >= 5 else epoch_time

        # éªŒè¯é›†é¢„æµ‹
        y_pred_proba = self.model.predict(self.X_val, verbose=0, batch_size=BATCH_SIZE)
        y_pred = np.argmax(y_pred_proba, axis=1)

        # è®¡ç®—å…³é”®æŒ‡æ ‡
        accuracy = accuracy_score(self.y_val, y_pred)
        map50 = self.calculate_map50(self.y_val, y_pred_proba)

        # å„ç±»åˆ«ç²¾åº¦å’Œå¬å›ç‡
        class_precision = precision_score(self.y_val, y_pred, average=None, zero_division=0)
        class_recall = recall_score(self.y_val, y_pred, average=None, zero_division=0)
        class_f1 = f1_score(self.y_val, y_pred, average=None, zero_division=0)

        # æ›´æ–°æœ€ä½³æŒ‡æ ‡
        if map50 > self.best_map50:
            self.best_map50 = map50
        if accuracy > self.best_accuracy:
            self.best_accuracy = accuracy

        # æ‰“å°è¯¦ç»†æŒ‡æ ‡
        print(f"\nğŸ¯ Epoch {epoch + 1:03d} è¯¦ç»†æŒ‡æ ‡:")
        print(f"   â±ï¸  æ—¶é—´: {epoch_time:.1f}s (å¹³å‡: {avg_time:.1f}s)")
        print(f"   ğŸ“Š å‡†ç¡®ç‡: {accuracy:.4f} | æœ€ä½³: {self.best_accuracy:.4f}")
        print(f"   ğŸ¯ mAP@50: {map50:.4f} | æœ€ä½³: {self.best_map50:.4f}")
        print(f"   ğŸ“ˆ æŸå¤±: {logs.get('loss', 0):.4f} | éªŒè¯æŸå¤±: {logs.get('val_loss', 0):.4f}")

        # æ‰“å°å„ç±»åˆ«æŒ‡æ ‡
        print(f"   ğŸª å„ç±»åˆ«æ€§èƒ½:")
        for i, class_name in enumerate(self.class_names_cn):
            print(f"     {class_name}: ç²¾åº¦={class_precision[i]:.3f}, å¬å›={class_recall[i]:.3f}, F1={class_f1[i]:.3f}")

        # å­¦ä¹ ç‡ä¿¡æ¯
        current_lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))
        print(f"   ğŸ“š å­¦ä¹ ç‡: {current_lr:.6f}")

    def calculate_map50(self, y_true, y_pred_proba):
        """è®¡ç®—mAP@50"""
        aps = []
        for class_idx in range(NUM_CLASSES):
            binary_labels = (y_true == class_idx).astype(int)
            class_probs = y_pred_proba[:, class_idx]
            ap = average_precision_score(binary_labels, class_probs)
            aps.append(ap)
        return np.mean(aps) if aps else 0


class ProgressLogger(Callback):
    """è®­ç»ƒè¿›åº¦è®°å½•å™¨"""

    def on_train_begin(self, logs=None):
        self.start_time = time.time()
        print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 80)

    def on_train_end(self, logs=None):
        total_time = time.time() - self.start_time
        print(f"\nâœ… è®­ç»ƒå®Œæˆ! æ€»æ—¶é—´: {total_time / 60:.1f} åˆ†é’Ÿ")
        print("=" * 80)


# ========================== æ”¹è¿›çš„ç‰¹å¾æå– ==========================
def improved_preprocess_image(image):
    """æ”¹è¿›çš„å›¾åƒé¢„å¤„ç†"""
    # è°ƒæ•´å¤§å°
    image = cv2.resize(image, IMG_SIZE)

    # å¯¹æ¯”åº¦å¢å¼º
    if len(image.shape) == 3:
        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        lab[:, :, 0] = cv2.createCLAHE(clipLimit=2.0).apply(lab[:, :, 0])
        image = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)

    # å™ªå£°å»é™¤
    image = cv2.medianBlur(image, 3)

    return image


def extract_moment_features(image):
    """æå–çŸ©ç‰¹å¾"""
    try:
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()

        # è®¡ç®—HuçŸ©
        moments = cv2.moments(gray)
        hu_moments = cv2.HuMoments(moments).flatten()

        # å¯¹æ•°å˜æ¢
        for i in range(len(hu_moments)):
            if hu_moments[i] != 0:
                hu_moments[i] = -1 * np.sign(hu_moments[i]) * np.log10(np.abs(hu_moments[i]))

        # è®¡ç®—åƒç´ çŸ©
        pixel_moments = [
            np.mean(gray), np.std(gray), np.var(gray),
            moment(gray.flatten(), moment=3), moment(gray.flatten(), moment=4)
        ]

        return np.concatenate([hu_moments, pixel_moments])
    except:
        return np.zeros(12)  # 7ä¸ªHuçŸ© + 5ä¸ªåƒç´ çŸ©


def extract_enhanced_features(image):
    """æ”¹è¿›çš„ç‰¹å¾æå– - æé«˜ç‰¹å¾è´¨é‡"""
    try:
        # ä½¿ç”¨æ”¹è¿›çš„é¢„å¤„ç†
        image = improved_preprocess_image(image)

        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()

        features = []

        # 1. æ ¸å¿ƒç»Ÿè®¡ç‰¹å¾
        features.extend([
            np.mean(gray), np.std(gray), np.median(gray),
            np.percentile(gray, 25), np.percentile(gray, 75),
            np.percentile(gray, 90), moment(gray.flatten(), moment=3),
            moment(gray.flatten(), moment=4)
        ])

        # 2. LBPç‰¹å¾
        lbp = local_binary_pattern(gray, 8, 1, method='uniform')
        lbp_hist, _ = np.histogram(lbp, bins=10, range=(0, 10))
        lbp_hist = lbp_hist.astype("float") / (lbp_hist.sum() + 1e-6)
        features.extend(lbp_hist)

        # 3. GLCMç‰¹å¾
        glcm = graycomatrix(gray, distances=[1], angles=[0],
                            levels=256, symmetric=True, normed=True)
        glcm_props = ['contrast', 'correlation', 'energy', 'homogeneity']
        for prop in glcm_props:
            features.append(graycoprops(glcm, prop)[0, 0])

        # 4. å½¢çŠ¶ç‰¹å¾
        _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if contours:
            largest_contour = max(contours, key=cv2.contourArea)
            area = cv2.contourArea(largest_contour)
            perimeter = cv2.arcLength(largest_contour, True)
            if perimeter > 0:
                circularity = 4 * np.pi * area / (perimeter * perimeter)
                features.extend([area, perimeter, circularity])
            else:
                features.extend([0, 0, 0])
        else:
            features.extend([0, 0, 0])

        # 5. çŸ©ç‰¹å¾
        moment_features = extract_moment_features(image)
        features.extend(moment_features[:10])  # å–å‰10ä¸ªæœ€é‡è¦çš„çŸ©ç‰¹å¾

        return np.array(features)

    except Exception as e:
        print(f"ç‰¹å¾æå–é”™è¯¯: {str(e)}")
        return None


# ========================== æ•°æ®å¢å¼ºå‡½æ•° ==========================
def advanced_augment_image(image):
    """é«˜çº§æ•°æ®å¢å¼º"""
    augmented = []

    # åŸºç¡€å¢å¼º
    # éšæœºæ—‹è½¬
    angle = random.uniform(-15, 15)
    rows, cols = image.shape[:2]
    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)
    rotated = cv2.warpAffine(image, M, (cols, rows), borderMode=cv2.BORDER_REPLICATE)
    augmented.append(rotated)

    # éšæœºæ°´å¹³ç¿»è½¬
    if random.random() > 0.5:
        flipped = cv2.flip(image, 1)
        augmented.append(flipped)

    # éšæœºäº®åº¦è°ƒæ•´
    if random.random() > 0.5:
        brightness_factor = random.uniform(0.7, 1.3)
        if len(image.shape) == 3:
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
            hsv[:, :, 2] = np.clip(hsv[:, :, 2] * brightness_factor, 0, 255)
            brightened = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        else:
            brightened = np.clip(image * brightness_factor, 0, 255).astype(np.uint8)
        augmented.append(brightened)

    return augmented


def augment_dataset(original_path, output_path, target_multiplier=2):
    """å¢å¼ºæ•°æ®é›†"""
    if not os.path.exists(output_path):
        os.makedirs(output_path)

    total_original = 0
    total_augmented = 0

    for class_name in CLASS_NAMES:
        class_original_path = os.path.join(original_path, class_name)
        class_output_path = os.path.join(output_path, class_name)

        if not os.path.exists(class_output_path):
            os.makedirs(class_output_path)

        image_files = [f for f in os.listdir(class_original_path)
                       if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]

        if not image_files:
            print(f"è­¦å‘Š: ç±»åˆ« {class_name} ä¸­æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
            continue

        original_count = len(image_files)
        target_count = original_count * target_multiplier
        need_to_add = target_count - original_count

        if need_to_add <= 0:
            print(f"ç±»åˆ« {class_name} å·²æœ‰è¶³å¤Ÿå›¾ç‰‡ï¼Œæ— éœ€å¢å¼º")
            continue

        print(f"å¢å¼ºç±»åˆ« {class_name}: åŸå§‹{original_count}å¼ ï¼Œéœ€è¦å¢åŠ {need_to_add}å¼ ä»¥è¾¾åˆ°{target_count}å¼ ...")

        # å¤åˆ¶åŸå§‹å›¾ç‰‡
        for img_file in image_files:
            src = os.path.join(class_original_path, img_file)
            dst = os.path.join(class_output_path, img_file)
            image = cv2.imdecode(np.fromfile(src, dtype=np.uint8), cv2.IMREAD_COLOR)
            cv2.imencode(os.path.splitext(img_file)[1], image)[1].tofile(dst)

        # ç”Ÿæˆå¢å¼ºå›¾ç‰‡
        added = 0
        while added < need_to_add:
            img_file = random.choice(image_files)
            img_path = os.path.join(class_original_path, img_file)

            try:
                image = cv2.imdecode(np.fromfile(img_path, dtype=np.uint8), cv2.IMREAD_COLOR)
                if image is None:
                    continue

                augmented_images = advanced_augment_image(image)

                for aug_img in augmented_images:
                    if added >= need_to_add:
                        break

                    base_name, ext = os.path.splitext(img_file)
                    aug_filename = f"{base_name}_aug_{added}{ext}"
                    aug_path = os.path.join(class_output_path, aug_filename)

                    cv2.imencode(ext, aug_img)[1].tofile(aug_path)
                    added += 1
                    total_augmented += 1

            except Exception as e:
                print(f"å¤„ç†å›¾ç‰‡ {img_file} æ—¶å‡ºé”™: {str(e)}")
                continue

        total_original += original_count
        print(f"ç±»åˆ« {class_name} å¢å¼ºå®Œæˆ: å…±{target_count}å¼ å›¾ç‰‡")

    print(f"\næ•°æ®é›†å¢å¼ºå®Œæˆ: åŸå§‹{total_original}å¼ ï¼Œæ–°å¢{total_augmented}å¼ ï¼Œæ€»è®¡{total_original + total_augmented}å¼ ")
    return output_path


def load_specific_dataset(dataset_path, sample_ratio=1.0):
    """åŠ è½½æ•°æ®é›†"""
    features = []
    labels = []

    # å¤šçº¿ç¨‹å¤„ç†å‡½æ•°
    def process_image(img_path, class_idx):
        try:
            image = cv2.imdecode(np.fromfile(img_path, dtype=np.uint8), cv2.IMREAD_COLOR)
            if image is None:
                return None
            feat = extract_enhanced_features(image)
            if feat is not None:
                return (feat, class_idx)
        except Exception as e:
            print(f"å¤„ç†å›¾ç‰‡ {img_path} æ—¶å‡ºé”™: {str(e)}")
        return None

    for class_idx, class_name in enumerate(CLASS_NAMES):
        class_path = os.path.join(dataset_path, class_name)
        if not os.path.exists(class_path):
            print(f"è­¦å‘Š: ç±»åˆ«æ–‡ä»¶å¤¹ä¸å­˜åœ¨ - {class_path}")
            continue

        image_files = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]

        # å¯¹æ¯ä¸ªç±»åˆ«å•ç‹¬æŠ½æ ·
        if sample_ratio < 1.0 and len(image_files) > 0:
            sample_size = max(1, int(len(image_files) * sample_ratio))
            image_files = random.sample(image_files, sample_size)
            print(f"âš ï¸ å¿«é€ŸéªŒè¯ï¼š{class_name} ç±»åˆ«éšæœºæŠ½æ · {sample_ratio * 100}%ï¼Œä¿ç•™ {len(image_files)} å¼ ")

        if not image_files:
            print(f"è­¦å‘Š: ç±»åˆ« {class_name} çš„æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°ä»»ä½•å›¾ç‰‡æ–‡ä»¶")
            continue

        print(f"æ­£åœ¨åŠ è½½ {os.path.basename(dataset_path)} ä¸­çš„ {class_name} ç±»åˆ«ï¼Œå…± {len(image_files)} å¼ å›¾ç‰‡...")
        img_paths = [os.path.join(class_path, f) for f in image_files]

        # å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†å›¾ç‰‡
        with ThreadPoolExecutor(max_workers=min(8, os.cpu_count())) as executor:
            futures = [executor.submit(process_image, path, class_idx) for path in img_paths]
            for future in as_completed(futures):
                result = future.result()
                if result:
                    features.append(result[0])
                    labels.append(result[1])

    if not features:
        raise ValueError(f"æœªä» {dataset_path} åŠ è½½åˆ°ä»»ä½•æœ‰æ•ˆæ•°æ®")

    print(f"ä» {os.path.basename(dataset_path)} æˆåŠŸåŠ è½½ {len(features)} å¼ å›¾ç‰‡æ•°æ®")
    return np.array(features), np.array(labels)


# ========================== æ”¹è¿›çš„æ¨¡å‹æ¶æ„ ==========================
def build_advanced_model(input_dim):
    """æ„å»ºæ”¹è¿›çš„ç¥ç»ç½‘ç»œæ¨¡å‹"""
    model = Sequential([
        Dense(512, input_dim=input_dim, kernel_regularizer=l2(0.001)),
        BatchNormalization(),
        Activation('relu'),
        Dropout(0.3),

        Dense(256, kernel_regularizer=l2(0.001)),
        BatchNormalization(),
        Activation('relu'),
        Dropout(0.3),

        Dense(128, kernel_regularizer=l2(0.001)),
        BatchNormalization(),
        Activation('relu'),
        Dropout(0.2),

        Dense(64, kernel_regularizer=l2(0.001)),
        BatchNormalization(),
        Activation('relu'),
        Dropout(0.1),

        Dense(NUM_CLASSES, activation='softmax')
    ])

    # ä½¿ç”¨Adamä¼˜åŒ–å™¨
    optimizer = Adam(
        learning_rate=LEARNING_RATE,
        beta_1=0.9,
        beta_2=0.999,
        epsilon=1e-07
    )

    model.compile(
        loss='sparse_categorical_crossentropy',
        optimizer=optimizer,
        metrics=['accuracy']
    )

    return model


# ========================== æ”¹è¿›çš„å›è°ƒå‡½æ•° ==========================
def get_enhanced_callbacks(X_val, y_val):
    """è·å–å¢å¼ºçš„å›è°ƒå‡½æ•°"""
    return [
        EarlyStopping(
            monitor='val_accuracy',
            patience=15,
            restore_best_weights=True,
            mode='max',
            verbose=1
        ),

        ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=8,
            min_lr=1e-7,
            verbose=1
        ),

        ModelCheckpoint(
            MODEL_SAVE_PATH,
            monitor='val_accuracy',
            save_best_only=True,
            mode='max',
            verbose=1
        ),

        AdvancedTrainingMonitor((X_val, y_val), CLASS_NAMES_CN),
        ProgressLogger()
    ]


# ========================== è¯¦ç»†çš„æ€§èƒ½åˆ†æ ==========================
def detailed_performance_analysis(model, X_val, y_val, model_type='neural'):
    """è¯¦ç»†çš„æ€§èƒ½åˆ†æ"""
    if model_type == 'neural':
        y_pred_proba = model.predict(X_val, verbose=0, batch_size=BATCH_SIZE)
    else:
        y_pred_proba = model.predict_proba(X_val)

    y_pred = np.argmax(y_pred_proba, axis=1)
    confidences = np.max(y_pred_proba, axis=1)

    print("\n" + "=" * 80)
    print("ğŸ“Š è¯¦ç»†æ€§èƒ½åˆ†ææŠ¥å‘Š")
    print("=" * 80)

    # åŸºç¡€æŒ‡æ ‡
    accuracy = accuracy_score(y_val, y_pred)
    precision_macro = precision_score(y_val, y_pred, average='macro', zero_division=0)
    recall_macro = recall_score(y_val, y_pred, average='macro', zero_division=0)
    f1_macro = f1_score(y_val, y_pred, average='macro', zero_division=0)
    map50 = calculate_map50(y_val, y_pred_proba)

    print(f"ğŸ¯ æ•´ä½“æ€§èƒ½:")
    print(f"   å‡†ç¡®ç‡: {accuracy:.4f}")
    print(f"   ç²¾ç¡®ç‡ (macro): {precision_macro:.4f}")
    print(f"   å¬å›ç‡ (macro): {recall_macro:.4f}")
    print(f"   F1åˆ†æ•° (macro): {f1_macro:.4f}")
    print(f"   mAP@50: {map50:.4f}")
    print(f"   å¹³å‡ç½®ä¿¡åº¦: {np.mean(confidences):.4f}")

    # å„ç±»åˆ«è¯¦ç»†æŒ‡æ ‡
    print(f"\nğŸª å„ç±»åˆ«æ€§èƒ½:")
    class_precision = precision_score(y_val, y_pred, average=None, zero_division=0)
    class_recall = recall_score(y_val, y_pred, average=None, zero_division=0)
    class_f1 = f1_score(y_val, y_pred, average=None, zero_division=0)

    for i in range(NUM_CLASSES):
        class_mask = (y_val == i)
        class_accuracy = accuracy_score(y_val[class_mask], y_pred[class_mask]) if np.sum(class_mask) > 0 else 0
        class_avg_confidence = np.mean(confidences[class_mask]) if np.sum(class_mask) > 0 else 0

        print(f"   {CLASS_NAMES_CN[i]}:")
        print(f"     å‡†ç¡®ç‡: {class_accuracy:.4f}")
        print(f"     ç²¾ç¡®ç‡: {class_precision[i]:.4f}")
        print(f"     å¬å›ç‡: {class_recall[i]:.4f}")
        print(f"     F1åˆ†æ•°: {class_f1[i]:.4f}")
        print(f"     å¹³å‡ç½®ä¿¡åº¦: {class_avg_confidence:.4f}")

    # ç½®ä¿¡åº¦åˆ†æ
    print(f"\nğŸ“ˆ ç½®ä¿¡åº¦åˆ†å¸ƒåˆ†æ:")
    confidence_bins = [(0, 0.5), (0.5, 0.7), (0.7, 0.9), (0.9, 1.0)]
    confidence_labels = ['ä½(<0.5)', 'ä¸­(0.5-0.7)', 'é«˜(0.7-0.9)', 'å¾ˆé«˜(>0.9)']

    for (low, high), label in zip(confidence_bins, confidence_labels):
        count = np.sum((confidences >= low) & (confidences < high))
        percentage = count / len(confidences) * 100
        correct_count = np.sum(((confidences >= low) & (confidences < high)) & (y_pred == y_val))
        correct_percentage = correct_count / count * 100 if count > 0 else 0
        print(f"   {label}: {count}ä¸ª ({percentage:.1f}%), æ­£ç¡®ç‡: {correct_percentage:.1f}%")

    return y_pred, confidences, y_pred_proba


def calculate_map50(y_true, y_pred_proba):
    """è®¡ç®—mAP@50"""
    aps = []
    for class_idx in range(NUM_CLASSES):
        binary_labels = (y_true == class_idx).astype(int)
        class_probs = y_pred_proba[:, class_idx]
        ap = average_precision_score(binary_labels, class_probs)
        aps.append(ap)
    return np.mean(aps) if aps else 0


# ========================== æ”¹è¿›çš„è®­ç»ƒæµç¨‹ ==========================
def check_data_balance(y_train, y_val):
    """æ£€æŸ¥æ•°æ®å¹³è¡¡æ€§"""
    print("ğŸ“Š æ•°æ®åˆ†å¸ƒæ£€æŸ¥:")
    class_weights = {}

    for i, class_name in enumerate(CLASS_NAMES_CN):
        train_count = np.sum(y_train == i)
        val_count = np.sum(y_val == i)
        total_count = train_count + val_count

        # è®¡ç®—ç±»åˆ«æƒé‡ï¼ˆå¤„ç†ä¸å¹³è¡¡æ•°æ®ï¼‰
        if train_count > 0:
            weight = len(y_train) / (NUM_CLASSES * train_count)
            class_weights[i] = weight
        else:
            class_weights[i] = 1.0

        print(f"  {class_name}: è®­ç»ƒé›† {train_count} ä¸ª, éªŒè¯é›† {val_count} ä¸ª, æƒé‡: {class_weights[i]:.2f}")

    return class_weights


def plot_training_history(history):
    """ç»˜åˆ¶è®­ç»ƒå†å²"""
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))

    # æŸå¤±æ›²çº¿
    ax1.plot(history.history['loss'], label='è®­ç»ƒæŸå¤±', linewidth=2)
    ax1.plot(history.history['val_loss'], label='éªŒè¯æŸå¤±', linewidth=2)
    ax1.set_title('è®­ç»ƒä¸éªŒè¯æŸå¤±å¯¹æ¯”', fontsize=14, fontweight='bold')
    ax1.set_xlabel('è®­ç»ƒè½®æ¬¡')
    ax1.set_ylabel('æŸå¤±å€¼')
    ax1.legend()
    ax1.grid(True, linestyle='--', alpha=0.7)

    # å‡†ç¡®ç‡æ›²çº¿
    ax2.plot(history.history['accuracy'], label='è®­ç»ƒå‡†ç¡®ç‡', linewidth=2)
    ax2.plot(history.history['val_accuracy'], label='éªŒè¯å‡†ç¡®ç‡', linewidth=2)
    ax2.set_title('è®­ç»ƒä¸éªŒè¯å‡†ç¡®ç‡å¯¹æ¯”', fontsize=14, fontweight='bold')
    ax2.set_xlabel('è®­ç»ƒè½®æ¬¡')
    ax2.set_ylabel('å‡†ç¡®ç‡')
    ax2.legend()
    ax2.grid(True, linestyle='--', alpha=0.7)

    plt.tight_layout()
    plot_path = os.path.join(PLOT_SAVE_PATH, 'improved_training_history.png')
    plt.savefig(plot_path, dpi=300, bbox_inches='tight')
    plt.show()


def improved_training_workflow():
    """æ”¹è¿›çš„è®­ç»ƒæµç¨‹"""
    print("ğŸš€ å¼€å§‹é«˜çº§ç„Šæ¥ç¼ºé™·æ£€æµ‹æ¨¡å‹è®­ç»ƒ...")

    # åˆ›å»ºå¿…è¦ç›®å½•
    create_necessary_directories()

    # ä½¿ç”¨LabelMeæ•°æ®
    print("\n" + "=" * 80)
    print("ğŸ“ å¤„ç†LabelMeæ ‡æ³¨æ•°æ®...")

    # è½¬æ¢LabelMeæ•°æ®
    labelme_train_path, labelme_val_path = create_dataset_from_labelme()

    if labelme_train_path is None:
        print("âŒ LabelMeæ•°æ®å¤„ç†å¤±è´¥ï¼Œé€€å‡ºè®­ç»ƒ")
        return

    # æ•°æ®å¢å¼º
    print("\n" + "=" * 80)
    print("ğŸ”„ æ•°æ®å¢å¼ºå¤„ç†...")
    augmented_train_path = augment_dataset(labelme_train_path, AUGMENTED_TRAIN_PATH, target_multiplier=2)
    augmented_val_path = augment_dataset(labelme_val_path, AUGMENTED_VAL_PATH, target_multiplier=2)

    # åŠ è½½æ•°æ®
    print("\n" + "=" * 80)
    print("ğŸ“‚ åŠ è½½è®­ç»ƒæ•°æ®...")
    try:
        X_train, y_train = load_specific_dataset(augmented_train_path, sample_ratio=0.05)
        X_val, y_val = load_specific_dataset(augmented_val_path, sample_ratio=0.05)
    except ValueError as e:
        print(f"âŒ é”™è¯¯: {e}")
        return

    # æ•°æ®å¹³è¡¡æ£€æŸ¥
    print("\nğŸ“Š æ•°æ®åˆ†å¸ƒæ£€æŸ¥:")
    class_weight_dict = check_data_balance(y_train, y_val)

    # ç‰¹å¾æ ‡å‡†åŒ–
    print("\nğŸ”§ ç‰¹å¾æ ‡å‡†åŒ–...")
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)
    joblib.dump(scaler, SCALER_SAVE_PATH)
    print(f"ç‰¹å¾ç»´åº¦: {X_train_scaled.shape[1]}")

    # è®­ç»ƒä¸»æ¨¡å‹
    print("\n" + "=" * 80)
    print("ğŸ§  è®­ç»ƒé«˜çº§ç¥ç»ç½‘ç»œæ¨¡å‹...")
    model = build_advanced_model(X_train_scaled.shape[1])

    # æ¨¡å‹æ¦‚è¦
    model.summary()

    # è®­ç»ƒæ¨¡å‹
    history = model.fit(
        X_train_scaled, y_train,
        epochs=EPOCHS,
        batch_size=BATCH_SIZE,
        validation_data=(X_val_scaled, y_val),
        callbacks=get_enhanced_callbacks(X_val_scaled, y_val),
        class_weight=class_weight_dict,
        verbose=1
    )

    # è¯¦ç»†æ€§èƒ½åˆ†æ
    print("\n" + "=" * 80)
    print("ğŸ“Š æœ€ç»ˆæ€§èƒ½åˆ†æ...")
    y_pred, confidences, y_pred_proba = detailed_performance_analysis(model, X_val_scaled, y_val, 'neural')

    # ä¿å­˜æ¨¡å‹
    model.save(MODEL_SAVE_PATH)
    print(f"\nğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {MODEL_SAVE_PATH}")

    # ç»˜åˆ¶è®­ç»ƒå†å²
    plot_training_history(history)

    print("\nâœ… è®­ç»ƒå®Œæˆï¼æ‰€æœ‰ä¼˜åŒ–å·²å®æ–½ã€‚")


def main():
    improved_training_workflow()


if __name__ == "__main__":
    main()
