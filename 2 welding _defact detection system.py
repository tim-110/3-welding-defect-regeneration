import os
import sys
import cv2
import joblib
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
import albumentations as A  # ç”¨äºæ•°æ®å¢å¼º

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# é…ç½®å‚æ•°
IMG_SIZE = (128, 128)
CLASS_NAMES = ['crack', 'porosity', 'spatter', 'good']
BATCH_SIZE = 32
EPOCHS = 50
MODEL_SAVE_PATH = "welding_defect_model.h5"
SCALER_SAVE_PATH = "feature_scaler.pkl"
AUGMENTED_TRAIN_DIR = "augmented_train_data"


class WeldingDefectDetector:
    def __init__(self):
        self.model = None
        self.class_names = CLASS_NAMES
        self.scaler = StandardScaler()
        self.is_trained = False

    def augment_image(self, image):
        """æ•°æ®å¢å¼º - åˆ›å»º10å€çš„å¢å¼ºå›¾åƒï¼ˆä¼˜åŒ–åï¼šæ¶ˆé™¤è­¦å‘Š+æ•´åˆé€»è¾‘ï¼‰"""
        transform = A.Compose([
            A.HorizontalFlip(p=0.5),  # æ°´å¹³ç¿»è½¬
            A.VerticalFlip(p=0.5),  # å‚ç›´ç¿»è½¬
            # ç”¨ Affine æ•´åˆâ€œæ—‹è½¬+å¹³ç§»+ç¼©æ”¾â€ï¼Œæ›¿ä»£ Rotate + ShiftScaleRotate
            A.Affine(
                rotate_limit=30,  # æ—‹è½¬èŒƒå›´Â±30Â°ï¼ˆè¦†ç›–åŸ Rotate çš„ 30Â°ï¼Œæ¯”åŸ ShiftScaleRotate çš„15Â°æ›´çµæ´»ï¼‰
                shift_limit=0.1,  # å¹³ç§»èŒƒå›´Â±10%ï¼ˆä¿ç•™åŸ ShiftScaleRotate çš„å¹³ç§»åŠŸèƒ½ï¼‰
                scale_limit=0.1,  # ç¼©æ”¾èŒƒå›´Â±10%ï¼ˆä¿ç•™åŸ ShiftScaleRotate çš„ç¼©æ”¾åŠŸèƒ½ï¼‰
                p=0.8  # 80%æ¦‚ç‡è§¦å‘ï¼ˆä¸åŸ Rotate ä¸€è‡´ï¼‰
            ),
            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),  # äº®åº¦/å¯¹æ¯”åº¦è°ƒæ•´
            A.GaussianBlur(blur_limit=(3, 7), p=0.3),  # é«˜æ–¯æ¨¡ç³Š
            A.ElasticTransform(alpha=1, sigma=50, p=0.3),  # å¼¹æ€§å½¢å˜
        ])
        # åç»­å¢å¼ºé€»è¾‘ï¼ˆç”Ÿæˆ10å€å›¾åƒï¼‰ä¸å˜...

        augmented_images = []
        for _ in range(10):  # åˆ›å»º10ä¸ªå¢å¼ºç‰ˆæœ¬
            augmented = transform(image=image)['image']
            augmented_images.append(augmented)

        return augmented_images

    def augment_dataset(self, original_data_dir, output_dir):
        """å¢å¼ºæ•´ä¸ªæ•°æ®é›†"""
        print(f"å¼€å§‹æ•°æ®å¢å¼º: {original_data_dir} -> {output_dir}")

        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        for class_name in self.class_names:
            class_input_dir = os.path.join(original_data_dir, class_name)
            class_output_dir = os.path.join(output_dir, class_name)

            if not os.path.exists(class_output_dir):
                os.makedirs(class_output_dir)

            if not os.path.exists(class_input_dir):
                print(f"âš ï¸ åŸå§‹ç±»åˆ«æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {class_input_dir}")
                continue

            image_files = [f for f in os.listdir(class_input_dir)
                           if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]

            print(f"å¢å¼ºç±»åˆ« {class_name}: {len(image_files)} å¼ åŸå§‹å›¾åƒ")

            for img_name in image_files:
                img_path = os.path.join(class_input_dir, img_name)
                image = cv2.imread(img_path)

                if image is None:
                    continue

                # ä¿å­˜åŸå§‹å›¾åƒ
                original_output_path = os.path.join(class_output_dir, f"original_{img_name}")
                cv2.imwrite(original_output_path, image)

                # ç”Ÿæˆå¢å¼ºå›¾åƒ
                augmented_images = self.augment_image(image)

                for i, aug_img in enumerate(augmented_images):
                    aug_output_path = os.path.join(class_output_dir, f"aug_{i}_{img_name}")
                    cv2.imwrite(aug_output_path, aug_img)

        print(f"âœ… æ•°æ®å¢å¼ºå®Œæˆ! è¾“å‡ºç›®å½•: {output_dir}")

    def preprocess_image(self, image):
        """é¢„å¤„ç†å›¾åƒ"""
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image

        # è°ƒæ•´å°ºå¯¸
        gray = cv2.resize(gray, IMG_SIZE)

        # é¢„å¤„ç†
        processed = cv2.GaussianBlur(gray, (5, 5), 0)
        processed = cv2.equalizeHist(processed)  # ç›´æ–¹å›¾å‡è¡¡åŒ–

        return processed

    def extract_advanced_features(self, image):
        """æå–æ›´ä¸°å¯Œçš„ç‰¹å¾"""
        # åŸºæœ¬ç»Ÿè®¡ç‰¹å¾
        mean_val = np.mean(image)
        std_val = np.std(image)
        min_val = np.min(image)
        max_val = np.max(image)

        # ç›´æ–¹å›¾ç‰¹å¾
        hist = cv2.calcHist([image], [0], None, [16], [0, 256])
        hist = hist.flatten() / hist.sum() if hist.sum() > 0 else hist.flatten()

        # è¾¹ç¼˜ç‰¹å¾
        edges = cv2.Canny(image, 100, 200)
        edge_density = np.sum(edges > 0) / edges.size

        # çº¹ç†ç‰¹å¾ - Sobel
        sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)
        sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)
        gradient_magnitude = np.sqrt(sobelx ** 2 + sobely ** 2)
        gradient_mean = np.mean(gradient_magnitude)
        gradient_std = np.std(gradient_magnitude)

        # çº¹ç†ç‰¹å¾ - LBP (ç®€åŒ–ç‰ˆ)
        lbp_features = self.calculate_simple_lbp(image)

        # ç»„åˆæ‰€æœ‰ç‰¹å¾
        features = [
            mean_val, std_val, min_val, max_val,
            edge_density, gradient_mean, gradient_std
        ]
        features.extend(hist[:8])  # å–å‰8ä¸ªç›´æ–¹å›¾ç‰¹å¾
        features.extend(lbp_features[:5])  # å–å‰5ä¸ªLBPç‰¹å¾

        return np.array(features)

    def calculate_simple_lbp(self, image):
        """è®¡ç®—ç®€åŒ–çš„LBPç‰¹å¾"""
        lbp = np.zeros_like(image, dtype=np.uint8)
        height, width = image.shape

        for i in range(1, height - 1):
            for j in range(1, width - 1):
                center = image[i, j]
                code = 0
                code |= (image[i - 1, j - 1] > center) << 7
                code |= (image[i - 1, j] > center) << 6
                code |= (image[i - 1, j + 1] > center) << 5
                code |= (image[i, j + 1] > center) << 4
                code |= (image[i + 1, j + 1] > center) << 3
                code |= (image[i + 1, j] > center) << 2
                code |= (image[i + 1, j - 1] > center) << 1
                code |= (image[i, j - 1] > center) << 0
                lbp[i, j] = code

        # è®¡ç®—LBPç›´æ–¹å›¾
        lbp_hist = cv2.calcHist([lbp], [0], None, [16], [0, 256])
        lbp_hist = lbp_hist.flatten() / lbp_hist.sum() if lbp_hist.sum() > 0 else lbp_hist.flatten()

        return lbp_hist

    def prepare_dataset(self, data_dir):
        """å‡†å¤‡æ•°æ®é›†"""
        print(f"ä» {data_dir} åŠ è½½æ•°æ®...")
        X = []
        y = []

        for i, class_name in enumerate(self.class_names):
            class_dir = os.path.join(data_dir, class_name)
            if not os.path.isdir(class_dir):
                print(f"âš ï¸  ç±»åˆ«æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {class_dir}")
                continue

            print(f"å¤„ç†ç±»åˆ«: {class_name}")

            image_files = [f for f in os.listdir(class_dir)
                           if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]

            if not image_files:
                print(f"âš ï¸  æ²¡æœ‰æ‰¾åˆ°å›¾åƒæ–‡ä»¶: {class_dir}")
                continue

            for img_name in image_files:
                img_path = os.path.join(class_dir, img_name)
                image = cv2.imread(img_path)

                if image is None:
                    continue

                # é¢„å¤„ç†
                processed = self.preprocess_image(image)

                # æå–ç‰¹å¾
                features = self.extract_advanced_features(processed)
                X.append(features)
                y.append(i)

        if len(X) == 0:
            print("âŒ æ²¡æœ‰æå–åˆ°ä»»ä½•ç‰¹å¾")
            return np.array([]), np.array([])

        print(f"âœ… æˆåŠŸæå– {len(X)} ä¸ªæ ·æœ¬çš„ç‰¹å¾")
        return np.array(X), np.array(y)

    def build_advanced_model(self, input_shape, num_classes):
        """æ„å»ºæ›´å¼ºå¤§çš„æ¨¡å‹ï¼ˆä¿®æ­£æŒ‡æ ‡é”™è¯¯ï¼‰"""
        # å¯¼å…¥å¤šåˆ†ç±»ä¸“ç”¨çš„ç²¾ç¡®ç‡å’Œå¬å›ç‡æŒ‡æ ‡
        from tensorflow.keras.metrics import (
            SparseCategoricalAccuracy,
            SparseCategoricalPrecision,
            SparseCategoricalRecall
        )

        model = models.Sequential([
            layers.Dense(128, activation='relu', input_shape=(input_shape,)),
            layers.BatchNormalization(),
            layers.Dropout(0.4),

            layers.Dense(64, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.3),

            layers.Dense(32, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.2),

            layers.Dense(num_classes, activation='softmax')
        ])

        model.compile(
            optimizer='adam',
            loss='sparse_categorical_crossentropy',
            # ä½¿ç”¨å¤šåˆ†ç±»ä¸“ç”¨æŒ‡æ ‡å‡½æ•°ï¼Œè€Œéå­—ç¬¦ä¸²
            metrics=[
                SparseCategoricalAccuracy(name='accuracy'),  # å‡†ç¡®ç‡
                SparseCategoricalPrecision(name='precision'),  # ç²¾ç¡®ç‡
                SparseCategoricalRecall(name='recall')  # å¬å›ç‡
            ]
        )

        return model

        return model

    def train(self, data_dir, validation_split=0.2):
        """è®­ç»ƒæ¨¡å‹"""
        print("å¼€å§‹æå–ç‰¹å¾...")
        X, y = self.prepare_dataset(data_dir)

        if len(X) == 0:
            print("âŒ æ— æ³•è®­ç»ƒï¼šæ²¡æœ‰æ•°æ®")
            return None

        print(f"æ•°æ®é›†å½¢çŠ¶: X={X.shape}, y={y.shape}")

        # åˆ’åˆ†è®­ç»ƒæµ‹è¯•é›†
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )

        print(f"è®­ç»ƒé›†: {X_train.shape[0]}, æµ‹è¯•é›†: {X_test.shape[0]}")

        # æ ‡å‡†åŒ–ç‰¹å¾
        self.scaler = StandardScaler()
        X_train = self.scaler.fit_transform(X_train)
        X_test = self.scaler.transform(X_test)

        # ä¿å­˜scaler
        joblib.dump(self.scaler, SCALER_SAVE_PATH)
        print(f"âœ… ç‰¹å¾æ ‡å‡†åŒ–å™¨å·²ä¿å­˜: {SCALER_SAVE_PATH}")

        # æ„å»ºæ¨¡å‹
        print("æ„å»ºæ¨¡å‹...")
        self.model = self.build_advanced_model(X_train.shape[1], len(self.class_names))
        self.model.summary()

        # è®¾ç½®å›è°ƒå‡½æ•°
        callbacks = [
            EarlyStopping(
                monitor='val_loss',
                patience=10,
                restore_best_weights=True,
                verbose=1
            ),
            ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.2,
                patience=5,
                min_lr=1e-6,
                verbose=1
            )
        ]

        # è®­ç»ƒæ¨¡å‹
        print("å¼€å§‹è®­ç»ƒæ¨¡å‹...model.compile")
        history = self.model.fit(
            X_train, y_train,
            epochs=EPOCHS,
            batch_size=BATCH_SIZE,
            validation_split=validation_split,
            callbacks=callbacks,
            verbose=1
        )

        # è¯„ä¼°æ¨¡å‹
        print("è¯„ä¼°æ¨¡å‹...")
        test_loss, test_accuracy, test_precision, test_recall = self.model.evaluate(X_test, y_test, verbose=0)
        print(f"ğŸ“Š æµ‹è¯•é›†å‡†ç¡®ç‡: {test_accuracy:.4f}")
        print(f"ğŸ“Š æµ‹è¯•é›†ç²¾ç¡®ç‡: {test_precision:.4f}")
        print(f"ğŸ“Š æµ‹è¯•é›†å¬å›ç‡: {test_recall:.4f}")

        # é¢„æµ‹å¹¶ç”Ÿæˆåˆ†ç±»æŠ¥å‘Š
        y_pred = self.model.predict(X_test)
        y_pred_classes = np.argmax(y_pred, axis=1)

        print("\nğŸ“‹ åˆ†ç±»æŠ¥å‘Š:")
        print(classification_report(y_test, y_pred_classes, target_names=self.class_names))

        print("\nğŸ“Š æ··æ·†çŸ©é˜µ:")
        print(confusion_matrix(y_test, y_pred_classes))

        # ä¿å­˜æ¨¡å‹
        self.model.save(MODEL_SAVE_PATH)
        self.is_trained = True
        print(f"âœ… æ¨¡å‹å·²ä¿å­˜: {MODEL_SAVE_PATH}")

        return history

    def predict_image(self, image_path):
        """é¢„æµ‹å•å¼ å›¾åƒçš„ç¼ºé™·ç±»å‹"""
        if not self.is_trained:
            # å°è¯•åŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹
            if os.path.exists(MODEL_SAVE_PATH) and os.path.exists(SCALER_SAVE_PATH):
                try:
                    self.model = models.load_model(MODEL_SAVE_PATH)
                    self.scaler = joblib.load(SCALER_SAVE_PATH)
                    self.is_trained = True
                    print("âœ… å·²åŠ è½½é¢„è®­ç»ƒæ¨¡å‹")
                except:
                    print("âŒ æ— æ³•åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹")
                    return None
            else:
                print("âŒ æ¨¡å‹æœªè®­ç»ƒï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹")
                return None

        # åŠ è½½å’Œé¢„å¤„ç†å›¾åƒ
        image = cv2.imread(image_path)
        if image is None:
            print(f"âŒ æ— æ³•è¯»å–å›¾åƒ: {image_path}")
            return None

        processed = self.preprocess_image(image)
        features = self.extract_advanced_features(processed)

        # æ ‡å‡†åŒ–ç‰¹å¾
        features_scaled = self.scaler.transform([features])

        # é¢„æµ‹
        prediction = self.model.predict(features_scaled, verbose=0)
        predicted_class = np.argmax(prediction)
        confidence = prediction[0][predicted_class]

        # æ˜¾ç¤ºç»“æœ
        result = {
            'class': self.class_names[predicted_class],
            'confidence': float(confidence),
            'all_probabilities': {
                cls: float(prob) for cls, prob in zip(self.class_names, prediction[0])
            }
        }

        print(f"\nğŸ” é¢„æµ‹ç»“æœ:")
        print(f"å›¾åƒ: {os.path.basename(image_path)}")
        print(f"é¢„æµ‹ç¼ºé™·ç±»å‹: {result['class']}")
        print(f"ç½®ä¿¡åº¦: {result['confidence']:.4f}")
        print("æ‰€æœ‰ç±»åˆ«æ¦‚ç‡:")
        for cls, prob in result['all_probabilities'].items():
            print(f"  {cls}: {prob:.4f}")

        # å¯è§†åŒ–ç»“æœ
        self.visualize_prediction(image, result)

        return result

    def visualize_prediction(self, image, result):
        """å¯è§†åŒ–é¢„æµ‹ç»“æœ"""
        plt.figure(figsize=(12, 5))

        # æ˜¾ç¤ºåŸå§‹å›¾åƒ
        plt.subplot(1, 2, 1)
        if len(image.shape) == 3:
            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        else:
            plt.imshow(image, cmap='gray')
        plt.title(f'Original Image\nPredicted: {result["class"]}\nConfidence: {result["confidence"]:.3f}')
        plt.axis('off')

        # æ˜¾ç¤ºæ¦‚ç‡åˆ†å¸ƒ
        plt.subplot(1, 2, 2)
        classes = list(result['all_probabilities'].keys())
        probabilities = list(result['all_probabilities'].values())

        colors = ['red' if prob == max(probabilities) else 'blue' for prob in probabilities]
        bars = plt.bar(classes, probabilities, color=colors, alpha=0.7)

        plt.title('Prediction Probabilities')
        plt.xlabel('Defect Classes')
        plt.ylabel('Probability')
        plt.xticks(rotation=45)
        plt.ylim(0, 1)

        # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, prob in zip(bars, probabilities):
            plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,
                     f'{prob:.3f}', ha='center', va='bottom')

        plt.tight_layout()
        plt.show()


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ç„Šæ¥ç¼ºé™·æ£€æµ‹ç³»ç»Ÿ")
    print("=" * 60)

    detector = WeldingDefectDetector()

    while True:
        print("\nè¯·é€‰æ‹©æ“ä½œ:")
        print("1. æ•°æ®å¢å¼º")
        print("2. è®­ç»ƒæ¨¡å‹")
        print("3. é¢„æµ‹å›¾åƒç¼ºé™·")
        print("4. é€€å‡º")

        choice = input("è¯·è¾“å…¥é€‰æ‹© (1/2/3/4): ").strip()

        if choice == "1":
            original_dir = input("è¯·è¾“å…¥åŸå§‹æ•°æ®ç›®å½•è·¯å¾„: ").strip()
            if os.path.exists(original_dir):
                detector.augment_dataset(original_dir, AUGMENTED_TRAIN_DIR)
            else:
                print("âŒ ç›®å½•ä¸å­˜åœ¨")

        elif choice == "2":
            data_dir = input("è¯·è¾“å…¥è®­ç»ƒæ•°æ®ç›®å½•è·¯å¾„ (ç›´æ¥å›è½¦ä½¿ç”¨å¢å¼ºæ•°æ®): ").strip()
            if not data_dir:
                data_dir = AUGMENTED_TRAIN_DIR

            if os.path.exists(data_dir):
                history = detector.train(data_dir)
                if history:
                    print("ğŸ‰ æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
            else:
                print("âŒ è®­ç»ƒæ•°æ®ç›®å½•ä¸å­˜åœ¨")

        elif choice == "3":
            image_path = input("è¯·è¾“å…¥è¦é¢„æµ‹çš„å›¾åƒè·¯å¾„: ").strip()
            if os.path.exists(image_path):
                result = detector.predict_image(image_path)
            else:
                print("âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨")

        elif choice == "4":
            print("å†è§!")
            break

        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")





if __name__ == "__main__":
    main()